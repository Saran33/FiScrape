{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read SQL table with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "from dateutil import parser\n",
    "from pytz import timezone\n",
    "from dateutil import parser\n",
    "\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from scrapy.exceptions import DropItem\n",
    "from FiScrape.models import Article, Tag, db_connect, create_table, Topic, Source, Author, SnipBlob, Blob, SnipVader, Vader #  create_output_table\n",
    "import logging\n",
    "# pip install -U textblob\n",
    "from textblob import TextBlob\n",
    "# pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con = 'sqlite:///FiScrape_01.db'\n",
    "con = 'sqlite:///FiScrape.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_table(\"article\", con, schema=None, index_col='id', coerce_float=True, parse_dates='published_date', chunksize=None) # columns=['headline, standfirst'],\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = 'headline'\n",
    "text = 'Ethereum Fixes Bitcoin'\n",
    "output = 'content'\n",
    "# output = 'article_link'\n",
    "\n",
    "article = df.loc[df[search].astype(str) == text]\n",
    "title = f\"{text.replace(' ', '_')}\"\n",
    "with open(f'{title}.txt','w') as f :\n",
    "    for line in article[output]:\n",
    "        f.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bleach\n",
    "def bleach_html(text):\n",
    "    tags = ['p', 'li', 'strong', 'b', 'em', 'u', 'i', 'mark', 's', 'sub', 'br', 'blockquote', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'small']\n",
    "    attrs = [None]\n",
    "    return bleach.clean(text, tags=tags, attributes=attrs, strip=True)\n",
    "\n",
    "for line in article[output].values:\n",
    "    better_text = bleach_html(line)\n",
    "    print (better_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def strp_class(text):\n",
    "#     \"\"\"Strips the class attribute from HTML tags.\"\"\"\n",
    "#     # cl_at = re.search(r\"[a-zA-Z0-9:;\\.\\s\\(\\)\\-\\,]*\", text)\n",
    "#     for match in re.finditer(r\"[a-zA-Z0-9:;\\.\\s\\(\\)\\-\\,]*\", text):\n",
    "#         print (match)\n",
    "\n",
    "# # def strp_class(text):\n",
    "# #     \"\"\"Strips the class attribute from HTML tags.\"\"\"\n",
    "# #     # cl_at = re.search(r\"[a-zA-Z0-9:;\\.\\s\\(\\)\\-\\,]*\", text)\n",
    "# #     for match in re.finditer(r\"[a-zA-Z0-9:;\\.\\s\\(\\)\\-\\,]*\", text):\n",
    "# #         text = re.sub(match, '', text)s\n",
    "# #     return text\n",
    "\n",
    "# for line in article[output]:\n",
    "#     clean = strp_class(line)\n",
    "#     print (clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as Bs\n",
    "\n",
    "for line in article[output].values:\n",
    "    src = Bs(line, features=\"html.parser\")\n",
    "    head_title = src.find('h2', {'id': 'firstHeading'})\n",
    "\n",
    "    print(head_title)\n",
    "    head_title.attrs.clear()\n",
    "    print(head_title)\n",
    "\n",
    "# src = Bs(article[output].values, features=\"html.parser\")\n",
    "# head_title = src.find('h2', {'id': 'firstHeading'})\n",
    "\n",
    "# print(head_title)\n",
    "# head_title.attrs.clear()\n",
    "# print(head_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_attrs(soup):\n",
    "    tag_list = soup.findAll(lambda tag: len(tag.attrs) > 0)\n",
    "    for t in tag_list:\n",
    "        for attr, val in t.attrs:\n",
    "            del t[attr]\n",
    "    return soup\n",
    "\n",
    "def example():\n",
    "    doc = article[output]\n",
    "    print ('Before:\\n%s' % doc)\n",
    "    soup = Bs(doc)\n",
    "    clean_soup = _remove_attrs(soup)\n",
    "    print ('After:\\n%s' % clean_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_input_attr(tag: Bs.element.Tag) -> None:\n",
    "    \"\"\"Remove a subset of attributes from a bs4 Tag\"\"\"\n",
    "    filter_attr_name_set = {'autocorrect', 'autofocus', 'border', 'disabled',\n",
    "                            'height', 'incremental', 'list', 'max', 'maxsize',\n",
    "                            'min', 'multiple', 'pattern', 'required', 'size',\n",
    "                            'step', 'tabindex', 'width'}\n",
    "    drop_key_set = set(tag.attrs) & filter_attr_name_set\n",
    "    for key in drop_key_set:\n",
    "        del tag.attrs[key]\n",
    "\n",
    "soup = Bs(open('sample.html'), features='lxml')\n",
    "for form in soup.find_all('form'):\n",
    "    filter_input_attr(form)\n",
    "    print(form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(article[output].values)\n",
    "article[output].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in article[output].values:\n",
    "    body = ''.join(line)\n",
    "print (body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for content in df['content']:\n",
    "    print (content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for standfirst in df['standfirst']:\n",
    "    print (standfirst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article_link in df['article_link']:\n",
    "    print (article_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in df['standfirst']:\n",
    "#     print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for row in df['standfirst']:\n",
    "# #     row = row.strip().replace(\"  \", \" \")\n",
    "# #     row = ' '.join(row.split())\n",
    "# #     row = row.replace(' .', '. ').replace(' ,', ',')\n",
    "# #     row = row + '.'\n",
    "# #     row = row.replace('..', '.').replace('.', '. ').strip()\n",
    "# #     print (row)\n",
    "\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x.strip().replace(\"  \", \" \").replace('  ', ' ').replace('  ', ' '))\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: ' '.join(x.split()))\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x.replace(' .', '. ').replace('.', '. ').replace(' ,', ','))\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x + '...').replace(' ...', '...').replace('......', '...')\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x.replace('?...', '?').replace('!...', '!').replace('-...', '-'))\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x.replace('. .', '.').strip())\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x.replace(':', ': ').replace(':  ', ': ').replace(' ;', ';'))\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x.replace('...', '... ').replace(' .', '... ').strip())\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x.replace('“ ', '“').replace(' ”','”').replace(\" ’\", \"’\").replace(\" ’\", \"’\"))\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x.strip().replace(\"  \", \" \").replace('  ', ' ').replace('  ', ' ')) \n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x.replace(' ... ..', '...').replace('......', '...').replace('..... ..', '...'))\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x.replace('......', '...').replace('....', '...'))\n",
    "# df['standfirst'] = df['standfirst'].apply(lambda x: x.replace('  ', ' '))\n",
    "\n",
    "# for row in df['standfirst']:\n",
    "#     print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_ = 57\n",
    "snippet = df['headline'][id_] +' - ...'+ df['standfirst'][id_]\n",
    "print (snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db_connect()\n",
    "create_table(engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "logging.info(\"****SentimentPipeline: database connected****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link =\"https://www.ft.com/content/31f7edf7-8e05-46e1-8b13-061532f8db5f\"\n",
    "session = Session()\n",
    "exist_article = session.query(Article).filter_by(article_link = link).first()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "exist_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exist_article.snip_blob['subjectivity']\n",
    "head = exist_article.headline\n",
    "sf = exist_article.standfirst\n",
    "text = ' — ...'.join([head,sf])\n",
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Bitcoin'\n",
    "\n",
    "class SentimentPipeline(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes database connection and sessionmaker.\n",
    "        Creates tables.\n",
    "        \"\"\"\n",
    "        engine = db_connect()\n",
    "        create_table(engine)\n",
    "        self.Session = sessionmaker(bind=engine)\n",
    "        logging.info(\"****SentimentPipeline: database connected****\")\n",
    "\n",
    "    def get_sentiment(self, item, spider):\n",
    "        \"\"\"\n",
    "        Calculates and stores sentiment scores for the snippet (headline & standfirst), and the article body, if it was scraped.\n",
    "        \"\"\"\n",
    "        session = self.Session()\n",
    "        exist_article = session.query(Article).filter_by(article_link = item[\"article_link\"]).first()\n",
    "        session.close()\n",
    "        if exist_article is not None:  # the current article exists\n",
    "            head = exist_article.headline\n",
    "            sf = exist_article.standfirst\n",
    "            text = ' — ...'.join([head,sf])\n",
    "\n",
    "            article = exist_article\n",
    "            snip_blob = SnipBlob(name=article.article_link)\n",
    "\n",
    "            subjectivity_score = self.get_subjectivity(text)\n",
    "            snip_blob.subjectivity = subjectivity_score\n",
    "            polarity_score = self.get_polarity(text)\n",
    "            snip_blob.polarity = polarity_score\n",
    "\n",
    "            snip_vader = SnipVader(name=article.article_link)\n",
    "            SIA = 0\n",
    "            SIA = self.get_SIA(text)\n",
    "            compound = (SIA['compound'])\n",
    "            neg = (SIA['neg'])\n",
    "            neu = (SIA['neu'])\n",
    "            pos = (SIA['pos'])\n",
    "            snip_vader.compound = compound\n",
    "            snip_vader.negative = neg\n",
    "            snip_vader.neutral = neu\n",
    "            snip_vader.negative = neg\n",
    "            \n",
    "        try:\n",
    "            # session.add(article)\n",
    "            session.commit()\n",
    "\n",
    "        except:\n",
    "            session.rollback()\n",
    "            raise\n",
    "\n",
    "        finally:\n",
    "            session.close()\n",
    "\n",
    "    # Get the subjectivity\n",
    "    def get_subjectivity(self, text):\n",
    "        \"\"\"\n",
    "        Returns a subjectivity score between 0 and 1.\n",
    "        0 is objective and 1 is subjective.\n",
    "        \"\"\"\n",
    "        return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "    # Get the polarity\n",
    "    def get_polarity(self, text):\n",
    "        \"\"\"\n",
    "        Returns a polarity score between -1 and 1.\n",
    "        -1 is negative sentiment and 1 is positive sentiment.\n",
    "        \"\"\"\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "\n",
    "    # Get the sentiment scores\n",
    "    def get_SIA(text):\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        sentiment =sia.polarity_scores(text)\n",
    "        return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the polarity\n",
    "def get_polarity(text):\n",
    "    \"\"\"\n",
    "    Returns a polarity score between -1 and 1.\n",
    "    -1 is negative sentiment and 1 is positive sentiment.\n",
    "    \"\"\"\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Get the subjectivity\n",
    "def get_subjectivity(text):\n",
    "    \"\"\"\n",
    "    Returns a subjectivity score between 0 and 1.\n",
    "    0 is objective and 1 is subjective.\n",
    "    \"\"\"\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def get_SIA(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment =sia.polarity_scores(text)\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_inp = \"Dalio warns regulators will ‘kill’ bitcoin if it becomes too successful Wood’s investment firm has unveiled plans for a bitcoin exchange traded fund, although it is yet to receive regulatory approval....\"\n",
    "text_inp = 'He said he will \"kill\" her slowly.'\n",
    "# text_inp = snippet\n",
    "print (text_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_inp = exist_article.standfirst\n",
    "# text_inp = text\n",
    "# text_inp = \"China expands crackdown by declaring all crypto activities ‘illegal’\"\n",
    "# text_inp = \"...have continued to invest in cryptocurrency using foreign platforms. The price of bitcoin fell more than 8 per cent immediately after the announcement, dropping to\"\n",
    "\n",
    "polarity = get_polarity(text_inp)\n",
    "subj = get_subjectivity(text_inp)\n",
    "SIA = get_SIA(text_inp)\n",
    "print (text_inp)\n",
    "print (\"Polarity:\", polarity, \"Subjectivity:\", subj)\n",
    "print(SIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = get_polarity(text_inp)\n",
    "subj = get_subjectivity(text_inp)\n",
    "SIA = get_SIA(text_inp)\n",
    "print (text_inp)\n",
    "print (\"Polarity:\", polarity, \"Subjectivity:\", subj)\n",
    "print(SIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = SIA['neg']\n",
    "neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_article.snip_blob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "497581ab8b68e3c2ef39c47d7e3c0ff119b32f5944e17571db2f7dc83154eb86"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('pwepip': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
